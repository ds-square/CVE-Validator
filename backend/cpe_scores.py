import os
import json

from flask import Flask
from flask import request
from flask import jsonify
from flask_cors import CORS

from urllib.parse import quote,unquote



## PROCESS VAR
snapshot_set = set()
snapshot_to_host_set = dict()
snapshot_to_host_data = dict()
snapshot_to_host_similarity = dict()



## PROCESS VAR INIT

# Requires ./data/meta.json
GENERAL_META = "data/meta.json"
if not os.path.isfile(GENERAL_META):
    print("File "+GENERAL_META+" not found, aborting")
    raise Exception("File "+GENERAL_META+" not found, aborting")

f = open(file=GENERAL_META,encoding="utf-8")
general_meta = json.loads(f.read())
f.close()

snapshot_set = set(general_meta["snapshots"])


for snapshot_id in snapshot_set:

    # Requires ./data/<snapshot_id>/snapshot_meta.json
    SNAPSHOT_META = "data/"+snapshot_id+"/snapshot_meta.json"
    if not os.path.isfile(SNAPSHOT_META):
        print("File "+SNAPSHOT_META+" not found, aborting")
        raise Exception("File "+SNAPSHOT_META+" not found, aborting")

    f = open(file=SNAPSHOT_META,encoding="utf-8")
    snapshot_meta = json.loads(f.read())
    f.close()

    snapshot_to_host_set[snapshot_id] = set(snapshot_meta["hosts"])



## START SERVER
app = Flask(__name__)
# CORS(app, send_wildcard=True)
CORS(app)

## CONTROLLER
# Root prints readme
@app.get("/")
def get_root():
    retval = "<html><head></head><body>"

    f = open("../README.md",encoding="utf-8")
    retval = retval + f.read()
    f.close()

    retval = retval.replace("\n","<br>")
    retval = retval + "</body></html>"

    return retval



# Snapshot list
@app.get("/snapshot/")
def get_snapshots():
    snapshot_return_list = list()
    for snapshot_id in snapshot_set:
        snapshot_return_list.append({"id":snapshot_id,"hostsCount":len(snapshot_to_host_set[snapshot_id])})
    return jsonify({'snapshots':snapshot_return_list}), 200



@app.get("/snapshot/<snapshot_id>")
def get_snapshot_by_id(snapshot_id):
    if snapshot_id in snapshot_to_host_set:
        host_return_list = list()
        for host_id in snapshot_to_host_set[snapshot_id]:
            cpe_coverage_value = 0
            cve_coverage_value = 0
            if is_host_in_cache(snapshot_id,host_id):
                # Get data
                host_data = host_cache_or_load(snapshot_id, host_id)
                # coverage = #Confirmed+Discarded_cve/#Total_cve
                cpe_coverage_value = (len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))/(len(host_data["open_cpe"])+len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))
                cve_coverage_value = (len(host_data["confirmed_cve"])+len(host_data["discarded_cve"]))/(len(host_data["open_cve"])+len(host_data["confirmed_cve"])+len(host_data["discarded_cve"]))
            # TODO brucia il coverage normale
            host_return_list.append({"id":host_id,"coverage":cve_coverage_value,"cve_coverage":cve_coverage_value,"platform_coverage":cpe_coverage_value})
        return jsonify({'id':snapshot_id,'hosts':host_return_list,"hostsCount":len(snapshot_to_host_set[snapshot_id])}), 200
    else:
        return "The snapshot with id ["+str(snapshot_id)+"] has not been found!",404



@app.get("/host/<snapshot_id>/<host_id>")
def get_host_by_id(snapshot_id, host_id):

    # Sanity checks
    if snapshot_id not in snapshot_to_host_set:
        return "The snapshot with id ["+str(snapshot_id)+"] has not been found!",404
    if host_id not in snapshot_to_host_set[snapshot_id]:
        return "The snapshot with id ["+str(snapshot_id)+"] has been found, however the host with id ["+str(host_id)+"] has not!",404

    # Get data
    host_data = host_cache_or_load(snapshot_id, host_id)

    # Return structure
    return_structure = dict()
    return_structure["id"] = host_id
    return_structure["platforms"] = list()
    return_structure["vulnerabilities"] = list()

    # TODO brucia il coverage normale
    return_structure["coverage"] = (len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))/(len(host_data["open_cpe"])+len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))
    return_structure["cve_coverage"] = (len(host_data["confirmed_cve"])+len(host_data["discarded_cve"]))/(len(host_data["open_cve"])+len(host_data["confirmed_cve"])+len(host_data["discarded_cve"]))
    return_structure["cpe_coverage"] = (len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))/(len(host_data["open_cpe"])+len(host_data["confirmed_cpe"])+len(host_data["discarded_cpe"]))

    for platform in order_cpe(host_data,host_data["open_cpe"]):
        cpe_wfn = cpe_to_wfn(platform)
        cpe_expectancy = len(host_data["cpe_to_advisory"][platform])/host_data["cpe_to_advisory_max"]
        ordering_score = cpe_ordering_metrics(host_data,platform)
        return_structure["platforms"].append({"id":platform,"expectancy":cpe_expectancy,"ordering_score":ordering_score,"wfn":cpe_wfn,"validated":"unknown"})
    for platform in host_data["confirmed_cpe"]:
        cpe_wfn = cpe_to_wfn(platform)
        cpe_expectancy = len(host_data["cpe_to_advisory"][platform])/host_data["cpe_to_advisory_max"]
        ordering_score = cpe_ordering_metrics(host_data,platform)
        return_structure["platforms"].append({"id":platform,"expectancy":cpe_expectancy,"ordering_score":ordering_score,"wfn":cpe_wfn,"validated":"confirmed"})
    for platform in host_data["discarded_cpe"]:
        cpe_wfn = cpe_to_wfn(platform)
        cpe_expectancy = len(host_data["cpe_to_advisory"][platform])/host_data["cpe_to_advisory_max"]
        ordering_score = cpe_ordering_metrics(host_data,platform)
        return_structure["platforms"].append({"id":platform,"expectancy":cpe_expectancy,"ordering_score":ordering_score,"wfn":cpe_wfn,"validated":"discarded"})

    for cve in host_data["confirmed_cve"]:
        return_structure["vulnerabilities"].append({"id":cve,"validated":"confirmed"})
    for cve in host_data["open_cve"]:
        return_structure["vulnerabilities"].append({"id":cve,"validated":"unknown"})
    for cve in host_data["discarded_cve"]:
        return_structure["vulnerabilities"].append({"id":cve,"validated":"discarded"})

    # Return
    return jsonify(return_structure)



@app.put("/host/<snapshot_id>/<host_id>")
def clone_host_from_source(snapshot_id, host_id):
    # Globals
    global snapshot_to_host_data
    
    # Request data
    request_data = request.get_json()

    """
    VALORE ATTESO
    {
        source: host_id_1
        target: host_id_2
    }
    """

    platform_id = platform_id.replace("FWD_SLSH_ENC","/") # Forward slash encoding apparently breaks flask

    # Payload sanity checks
    if ("source" not in request_data):
        return "'source' field not present in request json!", 400
    if ("target" not in request_data):
        return "'target' field not present in request json!", 400

    # Decode fields
    source_host_id = unquote(str(request_data["source"])).lower()
    target_host_id = unquote(str(request_data["target"])).lower()

    # Sanity checks
    if snapshot_id not in snapshot_to_host_set:
        return "The snapshot with id ["+str(snapshot_id)+"] has not been found!",404
    if target_host_id not in snapshot_to_host_set[snapshot_id]:
        return "The snapshot with id ["+str(snapshot_id)+"] has been found, however the host with id ["+str(target_host_id)+"] has not!",404
    if source_host_id not in snapshot_to_host_set[snapshot_id]:
        return "The snapshot with id ["+str(snapshot_id)+"] has been found, however the host with id ["+str(source_host_id)+"] has not!",404

    # Get data
    source_host_data = host_cache_or_load(snapshot_id, source_host_id)

    # Apply host data to target
    snapshot_to_host_data[snapshot_id][target_host_id] = source_host_data

    # Return Structure
    return_structure = dict()

    # Return
    return jsonify(return_structure)



@app.get("/platform/<snapshot_id>/<host_id>/<platform_id>")
def get_platform_by_id(snapshot_id, host_id, platform_id):

    platform_id = platform_id.replace("FWD_SLSH_ENC","/") # Forward slash encoding apparently breaks flask

    # Sanity checks
    if snapshot_id not in snapshot_to_host_set:
        return "The snapshot with id ["+str(snapshot_id)+"] has not been found!",404
    if host_id not in snapshot_to_host_set[snapshot_id]:
        return "The snapshot with id ["+str(snapshot_id)+"] has been found, however the host with id ["+str(host_id)+"] has not!",404

    # Get data
    host_data = host_cache_or_load(snapshot_id, host_id)

    # Return structure
    return_structure = dict()
    return_structure["id"] = platform_id
    return_structure["validated"] = "unknown"

    if (platform_id in host_data["open_cpe"]):
        return_structure["validated"] = "unknown"
    elif (platform_id in host_data["confirmed_cpe"]):
        return_structure["validated"] = "confirmed"
    elif (platform_id in host_data["discarded_cpe"]):
        return_structure["validated"] = "discarded"
    else:
        # If the CPE is not in any structure, we throw a 404
        return "The snapshot with id ["+str(snapshot_id)+"] and the host with id ["+str(host_id)+"] have been found, however the platform with id ["+str(platform_id)+"] has not!",404

    return_structure["wfn"] = cpe_to_wfn(platform_id)
    return_structure["expectancy"] = len(host_data["cpe_to_advisory"][platform_id])/host_data["cpe_to_advisory_max"]
    return_structure["ordering_score"] = cpe_ordering_metrics(host_data,platform_id)

    # Return
    return jsonify(return_structure)



@app.put("/platform/<snapshot_id>/<host_id>/<platform_id>")
def put_platform_by_id(snapshot_id, host_id, platform_id):
    # Globals
    global snapshot_to_host_data

    # Request data
    request_data = request.get_json()

    """
    VALORE ATTESO
    {
        validated: unknown|confirmed|discarded
    }
    """

    platform_id = platform_id.replace("FWD_SLSH_ENC","/") # Forward slash encoding apparently breaks flask

    # Sanity checks
    if snapshot_id not in snapshot_to_host_set:
        return "The snapshot with id ["+str(snapshot_id)+"] has not been found!",404
    if host_id not in snapshot_to_host_set[snapshot_id]:
        return "The snapshot with id ["+str(snapshot_id)+"] has been found, however the host with id ["+str(host_id)+"] has not!",404

    # Payload sanity checks
    #if ("id" not in request_data):
    #    return "'id' field not present in request json!", 400
    if ("validated" not in request_data):
        return "'validated' field not present in request json!", 400


    # Decode fields
    validated = unquote(str(request_data["validated"])).lower()

    # Payload format sanity check
    if (validated != "unknown") and (validated != "confirmed") and (validated != "discarded"):
        return "'validated' field has an unrecognized value ["+str(validated)+"]!\nAllowed vaues are unknown|confirmed|discarded", 400


    # Get data
    host_data = host_cache_or_load(snapshot_id, host_id)

    if (platform_id not in host_data["open_cpe"]) and (platform_id not in host_data["confirmed_cpe"]) and (platform_id not in host_data["discarded_cpe"]):
        # If the CPE is not in any structure, we throw a 404
        return "The snapshot with id ["+str(snapshot_id)+"] and the host with id ["+str(host_id)+"] have been found, however the platform with id ["+str(platform_id)+"] has not!",404

    if ((platform_id in host_data["open_cpe"]) and validated != "unknown") or ((platform_id in host_data["confirmed_cpe"]) and validated != "confirmed") or ((platform_id in host_data["discarded_cpe"]) and validated != "discarded"):
        # All sanity checks passed, run the numbers on the target host
        # dicts in python are thread safe as per documentation
        # flask dev server runs in threaded mode
        # production servers run in multiprocess, so there you will have to do something else
        host_data = run_the_circus(host_data,platform_id,validated)
        # Save the new configuration in cache
        snapshot_to_host_data[snapshot_id][host_id] = host_data
    else:
        print("WARN - PUT /platform/<"+snapshot_id+">/<"+host_id+">/<"+platform_id+"> not performed as platform is already ["+validated+"] !")


    # Process numerical fields
    cpe_wfn = cpe_to_wfn(platform_id)
    cpe_expectancy = len(host_data["cpe_to_advisory"][platform_id])/host_data["cpe_to_advisory_max"]
    ordering_score = cpe_ordering_metrics(host_data,platform_id)

    # Return
    return jsonify({'id':platform_id,'expectancy':cpe_expectancy,'ordering_score':ordering_score,'wfn':cpe_wfn,'validated':validated}), 200



# UNINTEGRATED COMMANDS BELOW
# USE CAUTION

# Reinitialize internal cache
# Used to reload all data from disk
@app.post("/admin/reinitialize")
def reinitialize_data():
    clear_host_cache()
    print("#### CLEARED PROGRESS ####")
    return "Ok",200



# Save command
# Should be non destructive
@app.post("/admin/save/<snapshot_id>/<host_id>")
def save_status(snapshot_id,host_id):

    # Get data
    host_data = host_cache_or_load(snapshot_id, host_id)

    # Perform save
    save_host_status_to_disk(snapshot_id, host_id,host_data)
    print("#### SAVED ####")
    return "Ok",200



# Calculate similarity matrix
@app.get("/admin/similarity_matrix/<snapshot_id>")
def similarity_matrix(snapshot_id):
    host_similarity_matrix = compute_host_similarity(snapshot_id)
    return host_similarity_matrix, 200



# Exit the program
@app.post("/admin/exit")
def exit_program():
    #exit()
    return "", 200



## HELPER FUNCTIONS

## LOADING

# Load from disk or from internal structure
# Lazy loading scheme
def host_cache_or_load(snapshot_id,host_id):
    # Import global vars
    global snapshot_to_host_data

    cached_data = dict()
    if is_host_in_cache(snapshot_id,host_id):
        cached_data = snapshot_to_host_data[snapshot_id][host_id]
    else:
        cached_data = host_cache_miss(snapshot_id,host_id)

        #cache data for next access
        if snapshot_id not in snapshot_to_host_data:
            snapshot_to_host_data[snapshot_id] = dict()

        snapshot_to_host_data[snapshot_id][host_id] = cached_data

    return cached_data



# Snapshot cache miss
def host_cache_miss(snapshot_id,host_id):
    # Load host

    # Requires ./data/<snapshot_id>/<host_id>/advisory_to_cve.json
    ADVISORY_TO_CVE = "data/"+snapshot_id+"/"+host_id+"/advisory_to_cve.json"
    if not os.path.isfile(ADVISORY_TO_CVE):
        print("File "+ADVISORY_TO_CVE+" not found, aborting")
        raise Exception("File "+ADVISORY_TO_CVE+" not found, aborting")

    # Requires ./data/<snapshot_id>/<host_id>/cve_to_cpe.json
    CVE_TO_CPE = "data/"+snapshot_id+"/"+host_id+"/cve_to_cpe.json"
    if not os.path.isfile(CVE_TO_CPE):
        print("File "+CVE_TO_CPE+" not found, aborting")
        raise Exception("File "+CVE_TO_CPE+" not found, aborting")

    # Requires ./data/<snapshot_id>/<host_id>/cpe_to_advisory.json
    CPE_TO_ADVISORY = "data/"+snapshot_id+"/"+host_id+"/cpe_to_advisory.json"
    if not os.path.isfile(CPE_TO_ADVISORY):
        print("File "+CPE_TO_ADVISORY+" not found, aborting")
        raise Exception("File "+CPE_TO_ADVISORY+" not found, aborting")
    
    # Requires ./data/<snapshot_id>/<host_id>/validation_inventory.json
    VALIDATION_INVENTORY = "data/"+snapshot_id+"/"+host_id+"/validation_inventory.json"
    if not os.path.isfile(VALIDATION_INVENTORY):
        print("File "+VALIDATION_INVENTORY+" not found, it will be generated on first save")



    #print("Retrieving Inventory data")
    # Grab data from metafiles
    f = open(file=ADVISORY_TO_CVE,mode="r",encoding="utf-8")
    advisory_to_cve_init = json.loads(f.read())
    f.close()

    f = open(file=CVE_TO_CPE,mode="r",encoding="utf-8")
    cve_to_cpe_dnf_tree_init = json.loads(f.read())
    f.close()

    f = open(file=CPE_TO_ADVISORY,mode="r",encoding="utf-8")
    cpe_to_advisory_init = json.loads(f.read())
    f.close()

    cpe_to_status_init = dict()
    if os.path.isfile(VALIDATION_INVENTORY):
        f = open(file=VALIDATION_INVENTORY,mode="r",encoding="utf-8")
        cpe_to_status_init = json.loads(f.read())
        f.close()



    # PROCESS VAR RESET
    # Inventory
    process_open_cve = set()
    process_confirmed_cve = set()
    process_discarded_cve = set()

    process_open_cpe = set()
    process_confirmed_cpe = set()
    process_discarded_cpe = set()

    process_advisory_to_cve = advisory_to_cve_init
    process_cpe_to_advisory = cpe_to_advisory_init

    process_cpe_to_advisory_max = 0

    # Trees
    process_cve_to_cpe_dnf_tree = cve_to_cpe_dnf_tree_init
    process_cve_to_cpe_dnf_tree_rolling = process_cve_to_cpe_dnf_tree

    # Scoring
    process_cve_to_cpe_to_true_score_max = dict()
    process_cve_to_cpe_to_true_score_freq = dict()
    process_cve_to_cpe_to_false_score = dict()

    process_cve_to_cpe_to_weighted_true_score_max = dict()
    process_cve_to_cpe_to_weighted_true_score_freq = dict()
    process_cve_to_cpe_to_weighted_false_score = dict()

    process_cve_to_cpe_to_combined_score_max = dict()
    process_cve_to_cpe_to_combined_score_freq = dict()

    # Election
    process_cve_to_elected_cpe_max = dict()
    process_cve_to_elected_cpe_freq = dict()

    # Cross CVE scoring
    process_cpe_to_mean_score = dict()
    process_cpe_to_sum_score = dict()
    process_cpe_to_cross_cve_score = dict()

    # PROCESS VAR INIT
    for cve in process_cve_to_cpe_dnf_tree:
        process_open_cve.add(cve)

    for cpe in process_cpe_to_advisory:
        process_cpe_to_advisory_max = max(process_cpe_to_advisory_max,len(process_cpe_to_advisory[cpe]))
        if cpe not in process_open_cpe:
            process_open_cpe.add(cpe)
        
    for cpe in cpe_to_status_init:
        if cpe_to_status_init[cpe] == "unknown":
            process_open_cpe.add(cpe)
        elif cpe_to_status_init[cpe] == "confirmed":
            process_confirmed_cpe.add(cpe)
        else:
            process_discarded_cpe.add(cpe)

    process_cve_to_cpe_to_true_score_max, process_cve_to_cpe_to_true_score_freq, process_cve_to_cpe_to_false_score = compute_true_false_score(process_cve_to_cpe_dnf_tree)
    process_cve_to_cpe_to_weighted_true_score_max, process_cve_to_cpe_to_weighted_true_score_freq, process_cve_to_cpe_to_weighted_false_score, process_cve_to_cpe_to_combined_score_max, process_cve_to_cpe_to_combined_score_freq = compute_weighted_true_false_score(process_cpe_to_advisory,process_cpe_to_advisory_max,process_cve_to_cpe_to_true_score_max,process_cve_to_cpe_to_true_score_freq,process_cve_to_cpe_to_false_score)
    process_cve_to_elected_cpe_max, process_cve_to_elected_cpe_freq = elect_cpe(process_cve_to_cpe_to_combined_score_max,process_cve_to_cpe_to_combined_score_freq)
    process_cpe_to_mean_score, process_cpe_to_sum_score, process_cpe_to_cross_cve_score = compute_mean_sum_score(process_cve_to_cpe_to_combined_score_max) #process_cve_to_cpe_to_combined_score_freq


    # Compile return structure

    host_data = dict()
    # Inventory
    host_data["open_cve"] = process_open_cve
    host_data["confirmed_cve"] = process_confirmed_cve
    host_data["discarded_cve"] = process_discarded_cve

    host_data["open_cpe"] = process_open_cpe
    host_data["confirmed_cpe"] = process_confirmed_cpe
    host_data["discarded_cpe"] = process_discarded_cpe

    host_data["advisory_to_cve"] = process_advisory_to_cve
    host_data["cpe_to_advisory"] = process_cpe_to_advisory

    host_data["cpe_to_advisory_max"] = process_cpe_to_advisory_max

    # Trees
    host_data["cve_to_cpe_dnf_tree"] = process_cve_to_cpe_dnf_tree
    host_data["cve_to_cpe_dnf_tree_rolling"] = process_cve_to_cpe_dnf_tree_rolling

    # Scoring
    host_data["cve_to_cpe_to_true_score_max"] = process_cve_to_cpe_to_true_score_max
    host_data["cve_to_cpe_to_true_score_freq"] = process_cve_to_cpe_to_true_score_freq
    host_data["cve_to_cpe_to_false_score"] = process_cve_to_cpe_to_false_score

    host_data["cve_to_cpe_to_weighted_true_score_max"] = process_cve_to_cpe_to_weighted_true_score_max
    host_data["cve_to_cpe_to_weighted_true_score_freq"] = process_cve_to_cpe_to_weighted_true_score_freq
    host_data["cve_to_cpe_to_weighted_false_score"] = process_cve_to_cpe_to_weighted_false_score

    host_data["cve_to_cpe_to_combined_score_max"] = process_cve_to_cpe_to_combined_score_max
    host_data["cve_to_cpe_to_combined_score_freq"] = process_cve_to_cpe_to_combined_score_freq

    # Election
    host_data["cve_to_elected_cpe_max"] = process_cve_to_elected_cpe_max
    host_data["cve_to_elected_cpe_freq"] = process_cve_to_elected_cpe_freq

    # Cross CVE scoring
    host_data["cpe_to_mean_score"] = process_cpe_to_mean_score
    host_data["cpe_to_sum_score"] = process_cpe_to_sum_score
    host_data["cpe_to_cross_cve_score"] = process_cpe_to_cross_cve_score


    # Check if any cpe has already been confirmed or discarded
    if (len(process_confirmed_cpe) > 0) or (len(process_discarded_cpe) > 0):
        # Oh no
        # This is bad, we need to recalculate the trees to see which CVE are still relevant

        # Call in the clowns
        # Note, passing a True value at the end avoids complete mayhem in the circus - I mean recalculation of the scores
        # Also, it pleases the clowns
        for platform_id in frozenset(process_confirmed_cpe):
            host_data = run_the_circus(host_data,platform_id,"confirmed",True)
        for platform_id in frozenset(process_discarded_cpe):
            host_data = run_the_circus(host_data,platform_id,"confirmed",True)

        # If we are still alive by this point, we have done a good job

        # Now we recalculate all the scores once
        host_data["cve_to_cpe_to_true_score_max"], host_data["cve_to_cpe_to_true_score_freq"], host_data["cve_to_cpe_to_false_score"] = compute_true_false_score(host_data["cve_to_cpe_dnf_tree_rolling"])
        host_data["cve_to_cpe_to_weighted_true_score_max"], host_data["cve_to_cpe_to_weighted_true_score_freq"], host_data["cve_to_cpe_to_weighted_false_score"], host_data["cve_to_cpe_to_combined_score_max"], host_data["cve_to_cpe_to_combined_score_freq"] = compute_weighted_true_false_score(host_data["cpe_to_advisory"],host_data["cpe_to_advisory_max"],host_data["cve_to_cpe_to_true_score_max"],host_data["cve_to_cpe_to_true_score_freq"],host_data["cve_to_cpe_to_false_score"])
        host_data["cve_to_elected_cpe_max"], host_data["cve_to_elected_cpe_freq"] = elect_cpe(host_data["cve_to_cpe_to_combined_score_max"],host_data["cve_to_cpe_to_combined_score_freq"])
        host_data["cpe_to_mean_score"], host_data["cpe_to_sum_score"], host_data["cpe_to_cross_cve_score"] = compute_mean_sum_score(host_data["cve_to_cpe_to_combined_score_max"])


    # Return data
    return host_data



# Simple check
def is_host_in_cache(snapshot_id,host_id):
    # Import global vars
    global snapshot_to_host_data

    # Check if in cache
    cache_hit = False
    if snapshot_id in snapshot_to_host_data:
        if host_id in snapshot_to_host_data[snapshot_id]:
            # Cache hit
            cache_hit = True

    # Return    
    return cache_hit



# Load from disk or internal structure, then forget
# Does not break lazy loading scheme
def host_load_and_forget(snapshot_id,host_id):
    # Import global vars
    global snapshot_to_host_data

    cached_data = dict()
    if is_host_in_cache(snapshot_id,host_id):
        cached_data = snapshot_to_host_data[snapshot_id][host_id]
    else:
        cached_data = host_cache_miss(snapshot_id,host_id)
        # Don't cache data
        
    return cached_data



# Clear cache
# Used for testin
def clear_host_cache():
    # Import global vars
    global snapshot_to_host_data

    snapshot_to_host_data = dict()



# Save to disk
def save_host_status_to_disk(snapshot_id, host_id, host_data):
    # Get platform status
    validation_inventory = dict()
    for platform_id in host_data["open_cpe"]:
        validation_inventory[platform_id] = "unknown"
    for platform_id in host_data["confirmed_cpe"]:
        validation_inventory[platform_id] = "confirmed"
    for platform_id in host_data["discarded_cpe"]:
        validation_inventory[platform_id] = "discarded"

    f = open(file="data/"+snapshot_id+"/"+host_id+"/validation_inventory.json",mode="w",encoding="utf-8")
    f.write(json.dumps(validation_inventory))
    f.close()




## ORCHESTRATION

# Orchestrate the internal process
def run_the_circus(host_data,platform_id,validated,unknown_recursive_step=False):
    new_host_data = host_data

    cpe = platform_id



    # Confirmed / Discarded handler
    if validated == "confirmed":
        # Confirmed

        # Edge case: is this cpe already discarded?
        if cpe in new_host_data["discarded_cpe"]:
            # Pass via unknown state first
            new_host_data = run_the_circus(new_host_data,platform_id,"unknown")

        new_host_data["open_cpe"].remove(cpe)
        new_host_data["confirmed_cpe"].add(cpe)
        new_process_cve_to_cpe_dnf_tree_rolling = dict()

        # Act on all CVE
        for other_cve in new_host_data["cve_to_cpe_dnf_tree_rolling"]:
            # Begin working on the rolling tree
            rolling_tree = new_host_data["cve_to_cpe_dnf_tree_rolling"][other_cve]
            new_rolling_tree = set()

            for and_elem in rolling_tree:
                if cpe in and_elem:
                    new_and = set(and_elem)
                    new_and.remove(cpe)
                    if len(new_and) > 0:
                        # AND with multiple elements, remove the confirmed one
                        new_rolling_tree.add(frozenset(new_and))
                    else:
                        # len = 0, confirm the CVE
                        # OR with one element, confirmed value
                        new_host_data["open_cve"].remove(other_cve)
                        new_host_data["confirmed_cve"].add(other_cve)
                        break
                else:
                    # CPE is not here, passthrough
                    new_rolling_tree.add(frozenset(and_elem))

            if other_cve in new_host_data["open_cve"]:
                new_process_cve_to_cpe_dnf_tree_rolling[other_cve] = new_rolling_tree

        new_host_data["cve_to_cpe_dnf_tree_rolling"] = new_process_cve_to_cpe_dnf_tree_rolling

    elif validated == "discarded":
        # Discarded

        # Edge case: is this cpe already confirmed?
        if cpe in new_host_data["confirmed_cpe"]:
            # Pass via unknown state first
            new_host_data = run_the_circus(new_host_data,platform_id,"unknown")

        new_host_data["open_cpe"].remove(cpe)
        new_host_data["discarded_cpe"].add(cpe)
        new_process_cve_to_cpe_dnf_tree_rolling = dict()

        # Act on all CVE
        for other_cve in new_host_data["cve_to_cpe_dnf_tree_rolling"]:
            # Begin working on the rolling tree
            rolling_tree = new_host_data["cve_to_cpe_dnf_tree_rolling"][other_cve]
            new_rolling_tree = set()

            for and_elem in rolling_tree:
                if cpe in and_elem:
                    # AND with multiple elements, kill the and
                    pass
                else:
                    # CPE is not here, passthrough
                    new_rolling_tree.add(frozenset(and_elem))

            if len(new_rolling_tree)>0:
                # are there any OR left?
                new_process_cve_to_cpe_dnf_tree_rolling[other_cve] = new_rolling_tree
            else:
                # no more OR left, discard the cve
                new_host_data["open_cve"].remove(other_cve)
                new_host_data["discarded_cve"].add(other_cve)

        new_host_data["cve_to_cpe_dnf_tree_rolling"] = new_process_cve_to_cpe_dnf_tree_rolling

    else:
        # Unknown

        # RANT
        # This is going to be a pain in the ass
        # I can't simply roll back
        # I need to reload everything
        # Then go through all choices and reapply them

        # I guess it's time to send in the clowns then..

        # Step 1: roll back the confirmed/discarded/open inventories
        if cpe in new_host_data["confirmed_cpe"]:
            new_host_data["confirmed_cpe"].remove(cpe)
        elif cpe in new_host_data["discarded_cpe"]:
            new_host_data["discarded_cpe"].remove(cpe)
        new_host_data["open_cpe"].add(cpe)

        # Step 2: roll back the tree to its original state
        new_host_data["cve_to_cpe_dnf_tree_rolling"] = new_host_data["cve_to_cpe_dnf_tree"]
        for other_cve in frozenset(new_host_data["confirmed_cve"]):
            new_host_data["confirmed_cve"].remove(other_cve)
            new_host_data["open_cve"].add(other_cve)
        for other_cve in frozenset(new_host_data["discarded_cve"]):
            new_host_data["discarded_cve"].remove(other_cve)
            new_host_data["open_cve"].add(other_cve)

        # Step 3: for each cpe in the confirmed/discarded inventory, apply the operation
        # NOTE: This is a recursive operation
        # NOTE: Never pass an unknown value here, or else the clowns will get very angry
        for other_cpe in frozenset(new_host_data["confirmed_cpe"]):
            new_host_data["open_cpe"].add(other_cpe) # The clowns demand this (look above for .remove)
            new_host_data = run_the_circus(new_host_data,other_cpe,"confirmed",True) # True tells the clowns to skip score recalculation
        for other_cpe in frozenset(new_host_data["discarded_cpe"]):
            new_host_data["open_cpe"].add(other_cpe) # The clowns demand this (look above for .remove)
            new_host_data = run_the_circus(new_host_data,other_cpe,"discarded",True) # True tells the clowns to skip score recalculation

        # Step 4: hopefully the circus is finished, the tigers didn't escape and the clowns are still happy
        # More importantly a new cve_to_cpe_dnf_tree_rolling has been calculated



    # Recalc everything
    if (unknown_recursive_step == False):
        new_host_data["cve_to_cpe_to_true_score_max"], new_host_data["cve_to_cpe_to_true_score_freq"], new_host_data["cve_to_cpe_to_false_score"] = compute_true_false_score(new_host_data["cve_to_cpe_dnf_tree_rolling"])
        new_host_data["cve_to_cpe_to_weighted_true_score_max"], new_host_data["cve_to_cpe_to_weighted_true_score_freq"], new_host_data["cve_to_cpe_to_weighted_false_score"], new_host_data["cve_to_cpe_to_combined_score_max"], new_host_data["cve_to_cpe_to_combined_score_freq"] = compute_weighted_true_false_score(new_host_data["cpe_to_advisory"],new_host_data["cpe_to_advisory_max"],new_host_data["cve_to_cpe_to_true_score_max"],new_host_data["cve_to_cpe_to_true_score_freq"],new_host_data["cve_to_cpe_to_false_score"])
        new_host_data["cve_to_elected_cpe_max"], new_host_data["cve_to_elected_cpe_freq"] = elect_cpe(new_host_data["cve_to_cpe_to_combined_score_max"],new_host_data["cve_to_cpe_to_combined_score_freq"])
        new_host_data["cpe_to_mean_score"], new_host_data["cpe_to_sum_score"], new_host_data["cpe_to_cross_cve_score"] = compute_mean_sum_score(new_host_data["cve_to_cpe_to_combined_score_max"])



    # Return
    return new_host_data



## SCORING

# True False score, no weights
def compute_true_false_score(cve_to_cpe_dnf_tree):
    # Null all the scores
    cve_to_cpe_to_true_score_max = dict()
    cve_to_cpe_to_true_score_freq = dict()
    cve_to_cpe_to_false_score = dict()

    for cve in cve_to_cpe_dnf_tree:
        # Scores are local, for every CPE in each CVE
        cve_to_cpe_to_true_score_max[cve] = dict()
        cve_to_cpe_to_true_score_freq[cve] = dict()
        cve_to_cpe_to_false_score[cve] = dict()

        max_and_degree = 1

        or_degree = len(cve_to_cpe_dnf_tree[cve])

        for and_cpe in cve_to_cpe_dnf_tree[cve]:
            and_degree = len(and_cpe)
            max_and_degree = max(max_and_degree,and_degree)

            for cpe in and_cpe:

                # Populate structures
                if cpe not in cve_to_cpe_to_true_score_max[cve]:
                    cve_to_cpe_to_true_score_max[cve][cpe] = 0
                    cve_to_cpe_to_true_score_freq[cve][cpe] = 0
                    cve_to_cpe_to_false_score[cve][cpe] = [0,0]

                # Apply the formulas
                cve_to_cpe_to_true_score_max[cve][cpe] = max(cve_to_cpe_to_true_score_max[cve][cpe], 1/and_degree)
                cve_to_cpe_to_true_score_freq[cve][cpe] = cve_to_cpe_to_true_score_freq[cve][cpe] + 1/and_degree
                cve_to_cpe_to_false_score[cve][cpe][0] = cve_to_cpe_to_false_score[cve][cpe][0] + 1
                cve_to_cpe_to_false_score[cve][cpe][1] = cve_to_cpe_to_false_score[cve][cpe][1] + and_degree

        # Normalize
        for cpe in cve_to_cpe_to_true_score_max[cve]:
            cve_to_cpe_to_true_score_max[cve][cpe] = cve_to_cpe_to_true_score_max[cve][cpe] / or_degree
            cve_to_cpe_to_true_score_freq[cve][cpe] = cve_to_cpe_to_true_score_freq[cve][cpe] / or_degree
            cve_to_cpe_to_false_score[cve][cpe] = (cve_to_cpe_to_false_score[cve][cpe][1]/max_and_degree) / or_degree
            #cve_to_cpe_to_false_score[cve][cpe] = (cve_to_cpe_to_false_score[cve][cpe][0] + (cve_to_cpe_to_false_score[cve][cpe][1]/max_and_degree)) / or_degree

    # Return
    return cve_to_cpe_to_true_score_max, cve_to_cpe_to_true_score_freq, cve_to_cpe_to_false_score



# True False score, weighted
def compute_weighted_true_false_score(cpe_to_advisory,cpe_to_advisory_max,cve_to_cpe_to_true_score_max,cve_to_cpe_to_true_score_freq,cve_to_cpe_to_false_score):
    # Null all the scores
    cve_to_cpe_to_weighted_true_score_max = dict()
    cve_to_cpe_to_weighted_true_score_freq = dict()
    cve_to_cpe_to_weighted_false_score = dict()

    cve_to_cpe_to_combined_score_max = dict()
    cve_to_cpe_to_combined_score_freq = dict()

    for cve in cve_to_cpe_to_true_score_max:
        # Scores are local, for every CPE in each CVE
        cve_to_cpe_to_weighted_true_score_max[cve] = dict()
        cve_to_cpe_to_weighted_true_score_freq[cve] = dict()
        cve_to_cpe_to_weighted_false_score[cve] = dict()

        cve_to_cpe_to_combined_score_max[cve] = dict()
        cve_to_cpe_to_combined_score_freq[cve] = dict()

        for cpe in cve_to_cpe_to_true_score_max[cve]:
            # Apply the formulas
            cve_to_cpe_to_weighted_true_score_max[cve][cpe] = ((len(cpe_to_advisory[cpe])/cpe_to_advisory_max)*cve_to_cpe_to_true_score_max[cve][cpe])
            cve_to_cpe_to_weighted_true_score_freq[cve][cpe] = ((len(cpe_to_advisory[cpe])/cpe_to_advisory_max)*cve_to_cpe_to_true_score_freq[cve][cpe])
            cve_to_cpe_to_weighted_false_score[cve][cpe] = ((1-(len(cpe_to_advisory[cpe])/cpe_to_advisory_max))*cve_to_cpe_to_false_score[cve][cpe])

            # S = a*T + b*F
            cve_to_cpe_to_combined_score_max[cve][cpe] = cve_to_cpe_to_weighted_true_score_max[cve][cpe] + cve_to_cpe_to_weighted_false_score[cve][cpe]
            cve_to_cpe_to_combined_score_freq[cve][cpe] = cve_to_cpe_to_weighted_true_score_freq[cve][cpe] + cve_to_cpe_to_weighted_false_score[cve][cpe]

    # Return
    return cve_to_cpe_to_weighted_true_score_max,cve_to_cpe_to_weighted_true_score_freq,cve_to_cpe_to_weighted_false_score,cve_to_cpe_to_combined_score_max, cve_to_cpe_to_combined_score_freq



# Elect CPE
def elect_cpe(cve_to_cpe_to_combined_score_max,cve_to_cpe_to_combined_score_freq):
    # Null all the scores
    cve_to_elected_cpe_max = dict()
    cve_to_elected_cpe_freq = dict()

    for cve in cve_to_cpe_to_combined_score_max:
        # Pick best cpe, for each cve
        max_score_max = 0
        max_score_freq = 0
        max_item_max = ""
        max_item_freq = ""

        for cpe in cve_to_cpe_to_combined_score_max[cve]:
            if max_score_max < cve_to_cpe_to_combined_score_max[cve][cpe]:
                max_score_max = cve_to_cpe_to_combined_score_max[cve][cpe]
                max_item_max = cpe
            if max_score_freq < cve_to_cpe_to_combined_score_freq[cve][cpe]:
                max_score_freq = cve_to_cpe_to_combined_score_freq[cve][cpe]
                max_item_freq = cpe

        cve_to_elected_cpe_max[cve] = max_item_max
        cve_to_elected_cpe_freq[cve] = max_item_freq

    # Return
    return cve_to_elected_cpe_max, cve_to_elected_cpe_freq



# Mean Sum score
def compute_mean_sum_score(cve_to_cpe_to_combined_score_max):
    # Initialize variables
    cpe_to_mean_score = dict()
    cpe_to_sum_score = dict()
    cpe_to_cross_cve_score = dict()

    # Counter
    cpe_counter = dict()

    for cve in cve_to_cpe_to_combined_score_max:
        for cpe in cve_to_cpe_to_combined_score_max[cve]:
            # Populate the dictionaries
            if cpe not in cpe_to_sum_score:
                cpe_to_sum_score[cpe] = 0
            if cpe not in cpe_counter:
                cpe_counter[cpe] = 0
            
            # Calculate the sum score
            cpe_to_sum_score[cpe] = cpe_to_sum_score[cpe] + cve_to_cpe_to_combined_score_max[cve][cpe]

            # Add to the counter
            cpe_counter[cpe] = cpe_counter[cpe] + 1

    # Mean score
    for cpe in cpe_to_sum_score:
        cpe_to_mean_score[cpe] = cpe_to_sum_score[cpe] / cpe_counter[cpe]

    # Final score
    for cpe in cpe_to_sum_score:
        cpe_to_cross_cve_score[cpe] = (cpe_to_sum_score[cpe]/len(cve_to_cpe_to_combined_score_max)) * cpe_to_mean_score[cpe]
        # RISK = LIKELIHOOD * IMPACT
        # LIKELIHOOD = SUM OF CPE IMPACTS [0-1] NORMALIZED ACROSS THE WHOLE CVE SET
        # IMPACT = CPE MEAN SCORE, WHEN CPE IS PRESENT

    # Return
    return cpe_to_mean_score, cpe_to_sum_score, cpe_to_cross_cve_score



# Host similarity
def compute_host_similarity(snapshot_id):
    # Globals
    global snapshot_to_host_similarity

    # Setup globals
    if snapshot_id not in snapshot_to_host_similarity:
        snapshot_to_host_similarity[snapshot_id] = dict()

    # Initialize structure
    host_similarity_matrix = dict()
    if snapshot_id in snapshot_to_host_set:
        for source_host_id in snapshot_to_host_set[snapshot_id]:
            host_similarity_matrix[source_host_id] = dict()
            for target_host_id in snapshot_to_host_set[snapshot_id]:
                host_similarity_matrix[source_host_id][target_host_id] = dict()
                host_similarity_matrix[source_host_id][target_host_id]["input_cve"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["open_cve"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_cve"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["discarded_cve"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cve"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["input_cpe"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["open_cpe"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_cpe"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["discarded_cpe"] = 0
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cpe"] = 0

    # Begin compilation of structure
    for source_host_id in snapshot_to_host_set[snapshot_id]:
        source_host_data = host_load_and_forget(snapshot_id, source_host_id)
        for target_host_id in snapshot_to_host_set[snapshot_id]:
            if source_host_id != target_host_id:
                target_host_data = host_load_and_forget(snapshot_id, target_host_id)

                # CVE metrics
                if max(len(source_host_data["open_cve"]),len(target_host_data["open_cve"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["open_cve"] = len(source_host_data["open_cve"].intersection(target_host_data["open_cve"]))/max(len(source_host_data["open_cve"]),len(target_host_data["open_cve"]))
                if max(len(source_host_data["confirmed_cve"]),len(target_host_data["confirmed_cve"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["confirmed_cve"] = len(source_host_data["confirmed_cve"].intersection(target_host_data["confirmed_cve"]))/max(len(source_host_data["confirmed_cve"]),len(target_host_data["confirmed_cve"]))
                if max(len(source_host_data["discarded_cve"]),len(target_host_data["discarded_cve"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["discarded_cve"] = len(source_host_data["discarded_cve"].intersection(target_host_data["discarded_cve"]))/max(len(source_host_data["discarded_cve"]),len(target_host_data["discarded_cve"]))
                if max(len(source_host_data["confirmed_cve"].union(source_host_data["discarded_cve"])),len(target_host_data["confirmed_cve"].union(target_host_data["discarded_cve"]))) != 0: host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cve"] = len(source_host_data["confirmed_cve"].union(source_host_data["discarded_cve"]).intersection(target_host_data["confirmed_cve"].union(target_host_data["discarded_cve"])))/max(len(source_host_data["confirmed_cve"].union(source_host_data["discarded_cve"])),len(target_host_data["confirmed_cve"].union(target_host_data["discarded_cve"])))
                if max(len(source_host_data["open_cve"].union(source_host_data["confirmed_cve"]).union(source_host_data["discarded_cve"])),len(target_host_data["open_cve"].union(target_host_data["confirmed_cve"]).union(target_host_data["discarded_cve"]))) != 0: host_similarity_matrix[source_host_id][target_host_id]["input_cve"] = len(source_host_data["open_cve"].union(source_host_data["confirmed_cve"]).union(source_host_data["discarded_cve"]).intersection(target_host_data["open_cve"].union(target_host_data["confirmed_cve"]).union(target_host_data["discarded_cve"])))/max(len(source_host_data["open_cve"].union(source_host_data["confirmed_cve"]).union(source_host_data["discarded_cve"])),len(target_host_data["open_cve"].union(target_host_data["confirmed_cve"]).union(target_host_data["discarded_cve"])))
                
                # CPE metrics
                if max(len(source_host_data["open_cpe"]),len(target_host_data["open_cpe"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["open_cpe"] = len(source_host_data["open_cpe"].intersection(target_host_data["open_cpe"]))/max(len(source_host_data["open_cpe"]),len(target_host_data["open_cpe"]))
                if max(len(source_host_data["confirmed_cpe"]),len(target_host_data["confirmed_cpe"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["confirmed_cpe"] = len(source_host_data["confirmed_cpe"].intersection(target_host_data["confirmed_cpe"]))/max(len(source_host_data["confirmed_cpe"]),len(target_host_data["confirmed_cpe"]))
                if max(len(source_host_data["discarded_cpe"]),len(target_host_data["discarded_cpe"])) != 0: host_similarity_matrix[source_host_id][target_host_id]["discarded_cpe"] = len(source_host_data["discarded_cpe"].intersection(target_host_data["discarded_cpe"]))/max(len(source_host_data["discarded_cpe"]),len(target_host_data["discarded_cpe"]))
                if max(len(source_host_data["confirmed_cpe"].union(source_host_data["discarded_cpe"])),len(target_host_data["confirmed_cpe"].union(target_host_data["discarded_cpe"]))) != 0: host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cpe"] = len(source_host_data["confirmed_cpe"].union(source_host_data["discarded_cpe"]).intersection(target_host_data["confirmed_cpe"].union(target_host_data["discarded_cpe"])))/max(len(source_host_data["confirmed_cpe"].union(source_host_data["discarded_cpe"])),len(target_host_data["confirmed_cpe"].union(target_host_data["discarded_cpe"])))
                if max(len(source_host_data["open_cpe"].union(source_host_data["confirmed_cpe"]).union(source_host_data["discarded_cpe"])),len(target_host_data["open_cpe"].union(target_host_data["confirmed_cpe"]).union(target_host_data["discarded_cpe"]))) != 0: host_similarity_matrix[source_host_id][target_host_id]["input_cpe"] = len(source_host_data["open_cpe"].union(source_host_data["confirmed_cpe"]).union(source_host_data["discarded_cpe"]).intersection(target_host_data["open_cpe"].union(target_host_data["confirmed_cpe"]).union(target_host_data["discarded_cpe"])))/max(len(source_host_data["open_cpe"].union(source_host_data["confirmed_cpe"]).union(source_host_data["discarded_cpe"])),len(target_host_data["open_cpe"].union(target_host_data["confirmed_cpe"]).union(target_host_data["discarded_cpe"])))
            else:
                # All values to 1
                host_similarity_matrix[source_host_id][target_host_id]["input_cve"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["open_cve"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_cve"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["discarded_cve"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cve"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["input_cpe"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["open_cpe"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_cpe"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["discarded_cpe"] = 1
                host_similarity_matrix[source_host_id][target_host_id]["confirmed_and_discarded_cpe"] = 1

    # Apply changes
    snapshot_to_host_similarity[snapshot_id] = host_similarity_matrix

    # Return
    return host_similarity_matrix



# Query host similarity
def query_host_similarity_source(snapshot_id,source_host_id):
    return_structure = dict()

    if snapshot_id in snapshot_to_host_similarity:
        if source_host_id in snapshot_to_host_similarity[snapshot_id]:
            for target_host_id in snapshot_to_host_similarity[snapshot_id][source_host_id]:
                return_structure[target_host_id] = snapshot_to_host_similarity[snapshot_id][source_host_id][target_host_id]

    return return_structure



# Query host similarity
def query_host_similarity_source_target(snapshot_id,source_host_id,target_host_id):
    if snapshot_id in snapshot_to_host_similarity:
        if source_host_id in snapshot_to_host_similarity[snapshot_id]:
            if target_host_id in snapshot_to_host_similarity[snapshot_id][source_host_id]:
                return snapshot_to_host_similarity[snapshot_id][source_host_id][target_host_id]
    return dict()



## FORMAT

# CPE unwinder
def cpe_to_wfn(cpe):
    return_struct = dict()
    return_struct["part"] = cpe[:cpe.find(":")]
    cpe = cpe[cpe.find(":")+1:]
    return_struct["vendor"] = cpe[:cpe.find(":")]
    return_struct["product"] = cpe[cpe.find(":")+1:]
    return_struct["version"] = "*"
    return_struct["update"] = "*"
    return_struct["edition"] = "*"
    return_struct["language"] = "*"
    return_struct["sw_edition"] = "*"
    return_struct["target_sw"] = "*"
    return_struct["target_hw"] = "*"
    return_struct["other"] = "*"
    return return_struct



# CPE ordering heuristic
def order_cpe(host_data,cpe_list):
    #cpe_list = list(cpe_list)


    def order_heur_sum(elem):
        score = 0

        if elem in host_data["cpe_to_sum_score"]:
            score = host_data["cpe_to_sum_score"][elem] / (len(host_data["open_cve"])+len(host_data["confirmed_cve"])+len(host_data["discarded_cve"]))

        return score


    def order_heur_mean_sum(elem):
        score = 0

#        for cve in host_data["cve_to_elected_cpe_max"]:
#            if elem == host_data["cve_to_elected_cpe_max"][cve]:
#                score = score + 1

        if elem in host_data["cpe_to_cross_cve_score"]:
            score = host_data["cpe_to_cross_cve_score"][elem]

        return score


    ret_list = sorted(cpe_list,key=order_heur_mean_sum,reverse=True)
    return ret_list



# CPE ordering metrics
def cpe_ordering_metrics(host_data,platform_id):
    metrics = dict()

    metrics["sum"] = 0
    metrics["mean"] = 0
    metrics["mean_times_sum"] = 0
    metrics["raw_scores"] = dict()

    if platform_id in host_data["cpe_to_cross_cve_score"]:
        metrics["sum"] = host_data["cpe_to_sum_score"][platform_id]
        metrics["mean"] = host_data["cpe_to_mean_score"][platform_id]
        metrics["mean_times_sum"] = host_data["cpe_to_cross_cve_score"][platform_id]
        for cve in host_data["cve_to_cpe_to_combined_score_max"]:
            if platform_id in host_data["cve_to_cpe_to_combined_score_max"][cve]:
                metrics["raw_scores"][cve] = host_data["cve_to_cpe_to_combined_score_max"][cve][platform_id]

    return metrics